---
title: "train_plier_canon"
author: "XSun"
date: "2020-09-14"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Introduction

In this part, I adopted lasso/elastic_net regression to train prediction models. The dependent variables here were LVs extracted from [plier-canonicalPathways](https://xsun1229.github.io/factor_analysis_DGN/factor_plier_canon.html) and the independent variables were genotype of certain variants. (LVs ~ variant genotype)

## Results

### Heritability vs R-squared

This figure shows the prediction performance (R2 of Lasso/Elastic_net regression on training set in red) in comparison to LV heritability estimates (black; standard errors in gray). Performance was assessed using tenfold cross-validation in the GTEx whole-blood cohort (on training set, n = 738) with the elastic net and lasso models.
  
<figure class="half">
    <img src="https://github.com/xsun1229/factor_analysis_DGN/raw/master/output/devide_snp001_le_pliercanon.jpeg" width="150%">
</figure>


### Summary of Heritability 

The table below shows the heritability of LVs and performance of the training models. The table has been sorted by Heritability from small to large.

Some notations to explain: **rsq_min** is the r-squared when lambda=lambda.min, **ncoef_nzero_min** is the number of non-zero coefficients when lambda=lambda.min, **rsq_test** is the r-squared in testing set (obtained from lm(lv.obs ~ lv.pred)) ,**pval_test** is the pvalue of F-statistics in testing set. When the suffix is '_1se', the notations mean lambda=lambda.1se. Suffix '_l' means lasso regression and '_e' means elastic_net


```{r eval=FALSE, echo=T}
  ###Lasso regression. 'k' represents the kth LV.
    fit_lasso <- cv.glmnet(x, y, alpha =1, foldid = foldid)   ##'foldid = foldid' can fix the data partition in cross validation, making the codes reproducible
    fit_r_train_l[k]  <- fit_lasso$glmnet.fit$dev.ratio[which(fit_lasso$glmnet.fit$lambda == fit_lasso$lambda.min)]  ###r2 when lambda = lambda.min
    predict_l <- predict(fit_lasso, nx, s = fit_lasso$lambda.min )
    
    fit_linear <- lm(y_test ~ predict_l)
    pval_test_l[i] <- summary(fit_linear)$coefficients[,4]
    rsq_test_l[i] <- summary(fit_linear)$r.squared

```

  

```{r echo=FALSE}
load("/project2/xinhe/xsun/website/factor_analysis_DGN/output/summary_H_le_sorted_pliercanon.rdata")
rownames(sum_sorted) <- c()
DT::datatable(sum_sorted, options = list(pageLength =20))

```

### LVs with relatively low pval_test_l

By sorting the pval_test_l in the table above, we can get several LVs that have very low pvalues on testing set (LV22,102). We made scatter plots of predicted LVs vs. observed LVs for them. Besides, we did GWAS analysis.

The red line in manhattan plot means p-value is 5e-8. 

#### lv22

<figure class="half">
    <img src="https://github.com/xsun1229/factor_analysis_DGN/raw/master/output/LV22_pliercanon.jpeg" width="200%">
</figure>

<figure class="half">
    <img src="https://github.com/xsun1229/factor_analysis_DGN/raw/master/output/qq_unif_lv22_pliercanon.jpeg" width="40%">
    <img src="https://github.com/xsun1229/factor_analysis_DGN/raw/master/output/man_lv22_pliercanon.jpeg" width="40%">
</figure>


#### lv102

<figure class="half">
    <img src="https://github.com/xsun1229/factor_analysis_DGN/raw/master/output/LV102_pliercanon.jpeg" width="200%">
</figure>

<figure class="half">
    <img src="https://github.com/xsun1229/factor_analysis_DGN/raw/master/output/qq_unif_lv102_pliercanon.jpeg" width="40%">
    <img src="https://github.com/xsun1229/factor_analysis_DGN/raw/master/output/man_lv102_pliercanon.jpeg" width="40%">
</figure>
